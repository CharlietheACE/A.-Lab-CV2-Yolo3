{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@author: Kunlun Wang \n",
    "#Created on 7/9/2020\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You guys are probably wondering, what the heck is TensorBoard? But let me ask you some questions first. Given the\n",
    "# previous codes, how do you determine how many conv/pooling layers you need to achieve the best outcome. How do you \n",
    "# know how many epoches you need? How do you know how many nodes you need in each layer? \n",
    "\n",
    "# To answer those question, we need to use TensorBoard. TensorBoard is a handy application that allows you to \n",
    "# view aspects of your model, or models, in your browser. I'll perform a demo for you guys to further understand \n",
    "# this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to make our TensorBoard callback object:\n",
    "NAME = \"active-vs-dormant-CNN-64*2-{}\".format(int(time.time()))\n",
    "\n",
    "# this will save the model's training data to logs/NAME, which can then be read by TensorBoard.\n",
    "tensorboard = TensorBoard(log_dir = 'log/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the feature set\n",
    "pickle_in = open(\"792020x.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the label set \n",
    "pickle_in = open(\"792020y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X=np.array(X/255.0)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers \n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers \n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should manipulate the model parameters to see what is the best parameterization for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280 samples, validate on 120 samples\n",
      "Epoch 1/10\n",
      "280/280 [==============================] - 2s 8ms/sample - loss: 0.7032 - accuracy: 0.4929 - val_loss: 0.6921 - val_accuracy: 0.6083\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6954 - val_accuracy: 0.3917\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6922 - accuracy: 0.5464 - val_loss: 0.7004 - val_accuracy: 0.3917\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6908 - accuracy: 0.5464 - val_loss: 0.7068 - val_accuracy: 0.3917\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6899 - accuracy: 0.5464 - val_loss: 0.7096 - val_accuracy: 0.3917\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6894 - accuracy: 0.5464 - val_loss: 0.7103 - val_accuracy: 0.3917\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6877 - accuracy: 0.5429 - val_loss: 0.6976 - val_accuracy: 0.4333\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6895 - accuracy: 0.5036 - val_loss: 0.7097 - val_accuracy: 0.3917\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6852 - accuracy: 0.5464 - val_loss: 0.7194 - val_accuracy: 0.3917\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 1s 3ms/sample - loss: 0.6836 - accuracy: 0.5500 - val_loss: 0.6998 - val_accuracy: 0.4917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63d1de390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "model.fit(X, y,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"congrats on fishing this tutorial\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
